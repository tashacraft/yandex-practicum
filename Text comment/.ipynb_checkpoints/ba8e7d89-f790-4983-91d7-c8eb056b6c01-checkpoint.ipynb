{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис, в котором пользователи могут редактировать и дополнять описания товаров как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "<b>Задача</b>: обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок. \n",
    "\n",
    "Метрика качества *F1* должна быть не меньше 0.75. \n",
    "\n",
    "<b>Данные</b> находятся в файле \"toxic_comments.csv\". В столбце \"text\" содержится текст комментариев, а в \"toxic\" — целевой признак (0 и 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика F1 - это среднегармоничное значение между precision и recall. В данном проекте заказчику важны и точность, и полнота. Точность - сколько действительно негативных комментариев модель отнесла к классу 1 и нейтральных к классу 0. А полнота - сколько модель нашла негативных комментариев среди всех негативных комментариев. В случае метрики F1 модель находит оптимальный баланс между точностью и полнотой.\n",
    "\n",
    "Если бы заказчику было важнее найти как можно больше токсичных комментариев, мы бы воспользовались метрикой Полнота(recall). В этом случае учтен был бы каждый токсичный комментарий, попавший или не попавший в класс 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-и-изучение-данных\" data-toc-modified-id=\"Подготовка-и-изучение-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка и изучение данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-и-изучение-данных\" data-toc-modified-id=\"Загрузка-и-изучение-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузка и изучение данных</a></span></li><li><span><a href=\"#Подготовка-данных-к-обучению\" data-toc-modified-id=\"Подготовка-данных-к-обучению-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Подготовка данных к обучению</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Мешок-слов\" data-toc-modified-id=\"Мешок-слов-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Мешок слов</a></span><ul class=\"toc-item\"><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>CatBoost</a></span></li><li><span><a href=\"#SGDClassifier\" data-toc-modified-id=\"SGDClassifier-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>SGDClassifier</a></span></li><li><span><a href=\"#Наивный-Байес\" data-toc-modified-id=\"Наивный-Байес-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Наивный Байес</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.1.6\"><span class=\"toc-item-num\">2.1.6&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#TF-IDF-кодирование\" data-toc-modified-id=\"TF-IDF-кодирование-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>TF-IDF кодирование</a></span><ul class=\"toc-item\"><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>CatBoost</a></span></li><li><span><a href=\"#SGDClassifier\" data-toc-modified-id=\"SGDClassifier-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>SGDClassifier</a></span></li><li><span><a href=\"#Наивный-Байес\" data-toc-modified-id=\"Наивный-Байес-2.2.5\"><span class=\"toc-item-num\">2.2.5&nbsp;&nbsp;</span>Наивный Байес</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.2.6\"><span class=\"toc-item-num\">2.2.6&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Эмбеддинги-BERT\" data-toc-modified-id=\"Эмбеддинги-BERT-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Эмбеддинги BERT</a></span></li></ul></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование модели</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка и изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и изучение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import warnings\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "# для лемматизации текста\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# для стоп-слов\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "# для лемматизации с POS тегом\n",
    "from nltk.corpus import wordnet\n",
    "# для подсчета самых частовстречающихся слов в корпусе\n",
    "from nltk.probability import FreqDist\n",
    "# разбитие текста на слова\n",
    "from nltk import word_tokenize\n",
    "# для создания \"облако тегов\"\n",
    "from wordcloud import WordCloud\n",
    "# для создания мешков слов\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# для использования TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# для разделения выборок\n",
    "from sklearn.model_selection import train_test_split\n",
    "# для перемешивания данных в выборке\n",
    "from sklearn.utils import shuffle\n",
    "# для подбора параметров GridSearchCV и кросс-валидации\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "# для создания pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# для вычисления F1-меры\n",
    "from sklearn.metrics import f1_score\n",
    "# для построения модели Случайный лес\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# для построения модели Логистическая регрессия\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# для построения модели SGD\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# для построения модели Наивный Байес\n",
    "from sklearn.naive_bayes import ComplementNB, BernoulliNB\n",
    "# для построения модели Метод опорных векторов\n",
    "from sklearn.svm import SVC\n",
    "# библиотека CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "# предобученная модель BERT и ее токенизатор\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# лемматизация\n",
    "nltk.download('wordnet')\n",
    "# делит текст на список предложений\n",
    "nltk.download('punkt')\n",
    "# удаление стоп-слов\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "# убрать вывод уведомлений\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('toxic_comments.csv', index_col=0)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['toxic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим на дубликаты\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет состоит из 159292 строк и 2 столбцов. В столбце \"text\" тексты на английском языке. В столбце \"toxic\" значения только 0 и 1. \n",
    "\n",
    "Данные в целевом признаке сохранены типом int64, можно заменить на int8 для уменьшения занимаемой памяти. \n",
    "Пропусков и дубликатов в данных нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "Хорошая попытка )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['toxic'] = data['toxic'].astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, каким комментариям (позитивным или негативным) соответствуют единицы и нули в столбце \"toxic\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('toxic == 1').sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('toxic == 0').sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Единицы - это токсичные (негативные) комментарии, нули - обычные или позитивные. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['toxic'].value_counts(normalize=True).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токсичных комментариев почти в 9 раз меньше, чем обычных. Выборка несбалансирована. Позже рассмотрим несколько способов борьбы с дисбалансом, обучим модели и сравним их качество.\n",
    "\n",
    "<b>Вывод</b>:\n",
    "- изучили данные, количество столбцов и строк\n",
    "- изменили тип данных в целевом признаке\n",
    "- пропусков и дубликатов нет\n",
    "- выборка несбалансированная\n",
    "- значение 1 в целевом признаке - это токсичный/негативный комментарий, 0 - нейтральный/позитивный\n",
    "- тексты с комментариями на английском языке, в текстах много мусора (спец.символы, знаки препинания)\n",
    "- можно приступать к подготовке данных к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Данные изучены. Небольшой EDA не помешает, так как это аналитический проект. \n",
    "\n",
    "\n",
    "Плюс за\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "-  проверку на сбалансированность \n",
    "\n",
    "\n",
    "\n",
    "- промужуточный вывод в конце раздела\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "- .sample вместо .head, ведь если данные каким то образом упорядоченны, то шансы увидеть что то разнообразное через .sample чуть выше чем через .head (или .tail)     \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background: #00ffff\">\n",
    "<b>Комментарий студента</b>\n",
    "    <br>Done<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим признаки и целевой признак перед обучением моделей. Напишем функции лемматизации и очистки текста (оставим только буквы латинского алфавита и пробелы). Также весь текст приведем к нижнему регистру.\n",
    "\n",
    "Для лемматизации используем библиотеку NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для определения части речи слова - POS tag\n",
    "def get_wordnet_pos(text):\n",
    "    tag = nltk.pos_tag([text])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция лемматизации\n",
    "def lemmatize(text):\n",
    "    text = text.lower()\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_list])  \n",
    "    return lemmatized_output\n",
    "\n",
    "# функция очистки текста от \"мусора\"\n",
    "def clear_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z']\", ' ', text)\n",
    "    return ' '.join(text.split()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "- WordNetLemmatizer  рабочий вариант, но у него есть особенности, для корректной работы ему нужно передавать не просто слово, но и POS-тег (Part of Speech, части речи). Набираемся ума-разума [тут](https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/) ) Обрати внимание на функцию `get_wordnet_pos`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background: #00ffff\">\n",
    "<b>Комментарий студента</b>\n",
    "    <br>Done!<br>Очень долго происходила лемматизация (<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "Мне тоже этот проект этим не нравится  (\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data['lemma'] = data['text'].apply(lambda x: lemmatize(clear_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим работу функций\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "\n",
    "- Плюс за использование apply, неэффективные циклы нам ни к чему.\n",
    "\n",
    "\n",
    "- Да, всегда лучше проверить что получилось  в итоге, так всегда будет возможность поправить ошбку\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "- после очистки и лемитизации можно провести частотный анализ текста/[облако слов](https://habr.com/ru/post/517410/) - чтобы получить общее представление о тематике и о наиболее часто встерчаемых словах Кроме того графики, рисунки делают проект визуально интересней\n",
    "    \n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы добавили столбец \"lemma\", в котором лемматизировали очищенные тексты из столбца \"text\". Создадим облако тегов - самые популярные слова в корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# соединим все тексты из data['lemma'] в одну строку\n",
    "text = \" \".join(comment for comment in data['lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разобьем текст на слова\n",
    "slova = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим стоп-слова\n",
    "slova = [word for word in slova if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитаем кол-во каждого слова\n",
    "fdist = FreqDist(slova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# топ-10 популярных слов\n",
    "fdist.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,8])\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "Красивое...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет 🤔:\n",
    "\n",
    "\n",
    "\n",
    "Ниже написал схему кода для облака в форме самолетика, забавно выглядит\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    !/opt/conda/bin/python -m pip install wordcloud\n",
    "    from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "    link = 'https://img2.freepng.ru/20180614/ygs/kisspng-airplane-aircraft-silhouette-clip-art-black-aircraft-5b220f2fe445a3.954015511528958767935.jpg'\n",
    "    os.system('wget %s'% link)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    stop_words = stopwords.words('english') # стоп-слова\n",
    "    text_cloud = ' '.join(df['lemm_text']) # соберем весь текст\n",
    "\n",
    "    # загружаем изображение и преобразуем в матрицу\n",
    "    cake_mask=np.array(Image.open('kisspng-airplane-aircraft-silhouette-clip-art-black-aircraft-5b220f2fe445a3.954015511528958767935.jpg'))\n",
    "\n",
    "    # сгенерируем облоко слов \n",
    "    cloud = WordCloud(stopwords=stop_words, mask=cake_mask, contour_width=10, contour_color='#2e3043', background_color='#272d3b', colormap='Set3', max_words=80).generate(text_cloud)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.imshow(cloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Теперь можно создать переменные для признаков и целевого признака и разбить датасет на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['lemma']\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=2501, stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим размеры выборок\n",
    "for i in (features_train, features_test, target_train, target_test):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "- random_state на месте\n",
    "\n",
    "    \n",
    "- плюс за  проверку\n",
    "    \n",
    "    \n",
    "- здорово что используешь stratify    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборки пропорционально изначальному датасету несбалансированные по классам. Попробуем обучить модели на несбалансированных данных, с параметром class_weight='balanced' и с использованием ресемплирования с уменьшением класса 0 (для \"тяжеловесных\"). Скорее всего на oversample датасете на валидационной выборке результат метрики F1 у моделей будет завышен, а на тестовой более низкий результат. Но проверить стоит 🙃\n",
    "\n",
    "Чтобы уменьшить выборку с нулевыми целевыми признаками, нужно:\n",
    "- разделить обучающую выборку на отрицательные и положительные объекты\n",
    "- случайным образом отбросить часть из отрицательных объектов\n",
    "- с учётом полученных данных создать новую обучающую выборку\n",
    "- перемешать данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background: #00ffff\">\n",
    "<b>Комментарий студента</b>\n",
    "    <br>Выше немного изменила обоснование использования ресемплирования датасета.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "Да теперь звучит как: \"Да, я понимаю некоторые недостатки метода..\" )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделили выборки на 0 и 1\n",
    "features_zeros = features_train[target_train == 0]\n",
    "features_ones = features_train[target_train == 1]\n",
    "target_zeros = target_train[target_train == 0]\n",
    "target_ones = target_train[target_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим размеры выборок\n",
    "for i in (features_zeros, features_ones, target_zeros, target_ones):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалили часть отрицательных ответов\n",
    "features_downsampled = pd.concat([features_zeros.sample(frac=0.11, random_state=2501)] \\\n",
    "                                 + [features_ones])\n",
    "target_downsampled = pd.concat([target_zeros.sample(frac=0.11, random_state=2501)] + \\\n",
    "                               [target_ones])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перемешали данные\n",
    "features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, \\\n",
    "                                                   random_state=2501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_downsampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_downsampled.plot(kind ='hist', bins=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_downsampled.shape)\n",
    "target_downsampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Рассмотрены разные варианты работы  с дисбалансом. Есть и критический взгляд на [oversampling](https://habr.com/ru/post/349078/), так ли он нужен?\n",
    "\n",
    "<div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет:\n",
    "\n",
    "валидационный датасет должен иметь первоначальный вид (я о пропорциях нулей и единичек), а у тебя он oversample, в итоге, на валидационном будет высокая метрика, но есть большие сомнения что на test будет хороший результат.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь наши выборки сбалансированы по классам.\n",
    "\n",
    "<b>Вывод</b>:\n",
    "- лемматизировали и очистили от мусора исходный текст комментариев\n",
    "- создали список самых частоупотребляемых слов и вывели \"облако тегов\"\n",
    "- создали переменные для признака и таргета\n",
    "- разделили данные на 4 выборки: 2 обучающие и 2 тестовые\n",
    "- сделали дополнительную разбивку выборок с ресемплированием для борьбы с дисбалансом классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Промежуточный вывод всегда в тему\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения моделей нам нужно закодировать признаки - сделать из слов вектора. Будем использовать 3 способа:\n",
    "- мешок слов\n",
    "- TF-IDF кодирование\n",
    "- создание BERT-эмбеддингов\n",
    "\n",
    "После векторизации обучим модели и найдем метрику F1 для каждой модели, выберем наилучшую модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем корпус текстов в мешок слов, создав счетчик\n",
    "count_vect = CountVectorizer(stop_words = stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "Решила стоп-слова не убирать?!\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background: #00ffff\">\n",
    "<b>Комментарий студента</b>\n",
    "    <br>Исправила<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "👍\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background: #00ffff\">\n",
    "<b>Комментарий студента</b>\n",
    "    <br>Ниже убрала обучение на ресемплированной выборке для всех моделей Случайного леса, Логистической регрессии. Оставила только на CatBoost и SGD - очень долго обучаются.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "👍\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для Случайного леса\n",
    "pipeline_forest = Pipeline(steps=[\n",
    "    ('vectorizer', count_vect),\n",
    "    ('dt_estimator', RandomForestClassifier(random_state=2501))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {'dt_estimator__max_depth': range(1, 7),\n",
    "              'dt_estimator__n_estimators': range(1, 42, 10)}\n",
    "\n",
    "grid_search_forest_bow = GridSearchCV(pipeline_forest, param_grid, cv=3, scoring='f1', n_jobs=1)\n",
    "grid_search_forest_bow.fit(features_train, target_train)\n",
    "f1_forest_bow = grid_search_forest_bow.best_score_\n",
    "\n",
    "print(f'F1 Случайного леса: {f1_forest_bow}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_forest_bow.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С несбалансированными выборками значение метрики F1 катастрофически низкое. Также обучение модели происходит достаточно долго (более 8 минут). Попробуем использовать агрумент class_weight='balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для Случайного леса с class_weight='balanced'\n",
    "pipeline_forest_cwb = Pipeline(steps=[\n",
    "    ('vectorizer', count_vect),\n",
    "    ('dt_estimator', RandomForestClassifier(random_state=2501, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {'dt_estimator__max_depth': range(1, 7),\n",
    "              'dt_estimator__n_estimators': range(1, 42, 10)}\n",
    "\n",
    "grid_search_forest_cwb_bow = GridSearchCV(pipeline_forest_cwb, param_grid, cv=3, scoring='f1', \\\n",
    "                                          n_jobs=1)\n",
    "grid_search_forest_cwb_bow.fit(features_train, target_train)\n",
    "f1_forest_cwb_bow = grid_search_forest_cwb_bow.best_score_\n",
    "\n",
    "print(f'F1 Случайного леса с class_weight=\"balanced\": {f1_forest_cwb_bow}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_forest_cwb_bow.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С аргументом class_weight='balanced' метрика улучшилась, но тоже очень низкая. Время обучения такое же."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "GridSearch + pipeline это уже другой уровень. Pipeline мало кто использует даже после совета, хотя он позволяет избежать утечки данных (особенно важно при использовании GridSearchCV/cross_val_score с предобработкой данных), и делает наш код лаконичней.\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет:\n",
    "\n",
    "Можно вообще все сразу подать в pipeline\n",
    "\n",
    "https://medium.com/@vinihcampos/predicting-blood-donations-with-supervised-learning-algorithms-298ea4045cfe\n",
    "    \n",
    "    \n",
    "    \n",
    "Но по моему не очень красиво так будет    \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background: #00ffff\">\n",
    "<b>Комментарий студента</b>\n",
    "    <br>Прочитала статью, спасибо! На мой взгляд, это очень громоздко. Python - должен легко читаться и пониматься. Мне проще несколько раз использовать pipeline.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "Согласен\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На прошлой модели явно видно, что с несбалансированными выборками модели обучаются намного хуже и медленнее. Далее будем использовать аргумент class_weight='balanced' для несбалансированных выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для Логистической регрессии\n",
    "pipeline_logreg = Pipeline(steps=[\n",
    "    ('vectorizer', count_vect),\n",
    "    ('dt_estimator', LogisticRegression(class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {'dt_estimator__max_iter': [1000],\n",
    "             'dt_estimator__solver':['newton-cg', 'lbfgs', 'liblinear'],\n",
    "             'dt_estimator__C': [0.1, 1, 10]}\n",
    "\n",
    "grid_search_log_cwb_bow = GridSearchCV(pipeline_logreg, param_grid, cv=3, scoring='f1', n_jobs=1)\n",
    "grid_search_log_cwb_bow.fit(features_train, target_train)\n",
    "f1_logreg_cwb_bow = grid_search_log_cwb_bow.best_score_\n",
    "\n",
    "print(f'F1 Логистической регрессии: {f1_logreg_cwb_bow}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_log_cwb_bow.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение F1 у Логистической регрессии на обучающей выборке чуть больше, чем надо для проекта. Скорость обучения заметно увеличилась по сравнению с обучением Случайного леса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для CatBoost\n",
    "pipeline_cat = Pipeline(steps=[\n",
    "    ('vectorizer', count_vect),\n",
    "    ('dt_estimator', CatBoostClassifier(eval_metric = 'F1', iterations=50, verbose=0, \\\n",
    "                                        random_state=2501, has_time=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель CatBoost очень долго обучалась на несбалансированной выборке, я не смогла дождаться результата. Поэтому принято решение использовать уменьшенную сбалансированную обучающую выборку. Проверим результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = [{\n",
    "    'dt_estimator__learning_rate': [0.03, 0.1],\n",
    "    'dt_estimator__depth': [1, 10],\n",
    "    'dt_estimator__l2_leaf_reg': [3, 5, 7, 9]\n",
    "}]\n",
    "\n",
    "grid_search_cat_down_bow = GridSearchCV(pipeline_cat, param_grid, cv=3, scoring='f1', n_jobs=1)\n",
    "grid_search_cat_down_bow.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "f1_catboost_down_bow = grid_search_cat_down_bow.best_score_\n",
    "\n",
    "print(f'F1 CatBoost: {f1_catboost_down_bow}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_cat_down_bow.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики F1 хорошее, но очень большое время обучения модели по сравнению с логистической регрессией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для SGDClassifier\n",
    "pipeline_sgd = Pipeline(steps=[\n",
    "    ('vectorizer', count_vect),\n",
    "    ('dt_estimator', SGDClassifier(random_state=2501, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели SGD также использовали уменьшенную сбалансированную обучающую выборку, так как обучение на несбалансированной очень долгое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = [{\n",
    "    'dt_estimator__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'dt_estimator__loss': ['hinge', 'log', 'modified_huber'],\n",
    "    'dt_estimator__eta0': [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "}]\n",
    "\n",
    "grid_search_sgd_down_bow = GridSearchCV(pipeline_sgd, param_grid, cv=3, scoring='f1', n_jobs=1)\n",
    "grid_search_sgd_down_bow.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "f1_sgd_down_bow = grid_search_sgd_down_bow.best_score_\n",
    "\n",
    "print(f'F1 SGD: {f1_sgd_down_bow}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_sgd_down_bow.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель SGDClassifier показала хороший результат, обучалась намного быстрее модели CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background: #00ffff\">\n",
    "<b>Комментарий студента</b>\n",
    "    <br>Ниже добавила новую модель: Наивный Байес. Метод опорных векторов у меня очень долго обучался - не дождалась (\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "👍\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наивный Байес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наивный Байес Complement\n",
    "pipeline_nbc = Pipeline(steps=[\n",
    "    ('vectorizer', count_vect),\n",
    "    ('dt_estimator', ComplementNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = [{\n",
    "    'dt_estimator__alpha': [1.0, 0.0, 0.5],\n",
    "    'dt_estimator__fit_prior': [True, False]\n",
    "}]\n",
    "\n",
    "grid_search_nbc_bow = GridSearchCV(pipeline_nbc, param_grid, cv=3, scoring='f1', n_jobs=1)\n",
    "grid_search_nbc_bow.fit(features_train, target_train)\n",
    "f1_nbc_bow = grid_search_nbc_bow.best_score_\n",
    "\n",
    "print(f'F1 Наивного Байеса Complement: {f1_nbc_bow}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_nbc_bow.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наивный Байес Complement обучился очень быстро, но метрика F1 достаточно низкая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наивный Байес Бернулли\n",
    "pipeline_nbc_ber = Pipeline(steps=[\n",
    "    ('vectorizer', count_vect),\n",
    "    ('dt_estimator', BernoulliNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = [{\n",
    "    'dt_estimator__alpha': [1.0, 0.0, 0.5],\n",
    "    'dt_estimator__fit_prior': [True, False]\n",
    "}]\n",
    "\n",
    "grid_search_nbc_ber_bow = GridSearchCV(pipeline_nbc_ber, param_grid, cv=3, scoring='f1', n_jobs=1)\n",
    "grid_search_nbc_ber_bow.fit(features_train, target_train)\n",
    "f1_nbc_ber_bow = grid_search_nbc_ber_bow.best_score_\n",
    "\n",
    "print(f'F1 Наивного Байеса Бернулли: {f1_nbc_ber_bow}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_nbc_ber_bow.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обе модели на основе Наивного Байеса (распределение Бернулли и мультиномиальное распределение) обучились мгновенно, но качество ответов не удовлетворяет нашему условию. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# соберем все в одной таблице\n",
    "total = pd.DataFrame(columns=['F1'],\n",
    "                    index=['Случайный лес несбаланс.выборки', \n",
    "                           'Случайный лес balanced', \n",
    "                           'Логистическая регрессия balanced',\n",
    "                           'CatBoost',\n",
    "                           'SGDClassifier',\n",
    "                          'Наивный Байес Complement',\n",
    "                          'Наивный Байес Бернулли'],\n",
    "                    data=[f1_forest_bow, f1_forest_cwb_bow, f1_logreg_cwb_bow,\n",
    "                          f1_catboost_down_bow, f1_sgd_down_bow, f1_nbc_bow, \n",
    "                          f1_nbc_ber_bow])\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total.sort_values(by='F1', ascending=False).plot.barh(y='F1', figsize=(12,5), color='green')\n",
    "plt.title('Сравнение F1 моделей')\n",
    "plt.xlabel('F1')\n",
    "plt.ylabel('Модель')\n",
    "plt.axvline(x=0.75, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе обучения моделей с помощью векторизации Мешок слов можно сделать следующие выводы:\n",
    "- на несбалансированных выборках модели обучаются очень медленно и показывают очень плохие результаты F1, было принято решение для обучения некоторых моделей использовать только сбалансированные выборки\n",
    "- модели Случайный лес, Наивный Байес показали F1 ниже заданного уровня\n",
    "- остальные модели показали на обучающей выборке метрики F1 выше требуемого 0.75\n",
    "- быстрее всех обучается модель Наивный Байес (менее 2-х минут), CatBoost обучается очень долго - более 36 минут, SGD - чуть более 5 минут\n",
    "- на данном этапе проекта для проверки на тестовых данных лучшая модель Логистическая регрессия, так как она показала метрику выше 0.75, обучалась на полном датасете и ее время обучения допустимое (чуть более 20 минут)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "👍\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF кодирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся другим способом кодирование признаков TF-IDF: TF отвечает за количество упоминаний слова в отдельном тексте, а IDF отражает частоту его употребления во всём корпусе. Вместе они дают оценку важности слова во всем корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объявляем векторизатор\n",
    "count_tf_idf = TfidfVectorizer(stop_words = stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Не забыли о стопсловах, они ни к чему и код побежит быстрей\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет:     \n",
    "\n",
    "Вопросик:\n",
    "\n",
    "А стопслова важней убирать  когда мы используем TF-IDF, или когда используе обычный CountVectorizer? \n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background: #00ffff\">\n",
    "<b>Комментарий студента</b>\n",
    "    <br>На мой взгляд, убирать стоп-слова важнее при векторизации Мешок слов, так как при этом методе не учитывается ни грамматика слова, ни части речи, ни порядок слов в предложении. Чем больше \"бессмысленных\" слов в тексте - тем для модели будет труднее отличить неважные признаки от важных и поэтому модель хуже обучится.<br><br>\n",
    "В методе TF-IDF для каждого слова назначается его вес, а для часто встречающихся \"бессмысленных\" слов типа \"the\" применяется штраф. Поэтому этому методу проще, но лучше все же использовать стоп слова 🙃<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "Всё верно\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для Случайного леса\n",
    "pipeline_forest = Pipeline(steps=[\n",
    "    ('vectorizer', count_tf_idf),\n",
    "    ('dt_estimator', RandomForestClassifier(random_state=2501))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {'dt_estimator__max_depth': range(1, 7),\n",
    "              'dt_estimator__n_estimators': range(1, 42, 10)}\n",
    "\n",
    "grid_search_forest_tf = GridSearchCV(pipeline_forest, param_grid, cv=3, scoring='f1', n_jobs=1)\n",
    "grid_search_forest_tf.fit(features_train, target_train)\n",
    "f1_forest_tf = grid_search_forest_tf.best_score_\n",
    "\n",
    "print(f'F1 Случайного леса: {f1_forest_tf}')\n",
    "print(f'Лучшие гиперпараметры: {grid_search_forest_tf.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и с мешком слов, модель Случайный лес на несбалансированной выборке совсем не справилась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для Случайного леса с class_weight='balanced'\n",
    "pipeline_forest_cwb_tf = Pipeline(steps=[\n",
    "    ('vectorizer', count_tf_idf),\n",
    "    ('dt_estimator', RandomForestClassifier(random_state=2501, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "grid_search_forest_cwb_tf = GridSearchCV(pipeline_forest_cwb_tf, param_grid, cv=3, scoring='f1', \\\n",
    "                                         n_jobs=1)\n",
    "grid_search_forest_cwb_tf.fit(features_train, target_train)\n",
    "f1_forest_cwb_tf = grid_search_forest_cwb_tf.best_score_\n",
    "\n",
    "print(f'F1 Случайного леса с class_weight=\"balanced\": {f1_forest_cwb_tf}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_forest_cwb_tf.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика F1 немного больше при TF-IDF, чем при мешке слов. Также скорость обучения моделей чуть выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для Логистической регрессии\n",
    "pipeline_logreg_tf = Pipeline(steps=[\n",
    "    ('vectorizer', count_tf_idf),\n",
    "    ('dt_estimator', LogisticRegression(class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {'dt_estimator__max_iter': [1000],\n",
    "             'dt_estimator__solver':['newton-cg', 'lbfgs', 'liblinear'],\n",
    "             'dt_estimator__C': [0.1, 1, 10]\n",
    "             }\n",
    "\n",
    "grid_search_logreg_cwb_tf = GridSearchCV(pipeline_logreg_tf, param_grid, cv=3, scoring='f1', n_jobs=1)\n",
    "grid_search_logreg_cwb_tf.fit(features_train, target_train)\n",
    "f1_logreg_cwb_tf = grid_search_logreg_cwb_tf.best_score_\n",
    "\n",
    "print(f'F1 Логистической регрессии: {f1_logreg_cwb_tf}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_logreg_cwb_tf.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель показала хороший результат F1 и быструю скорость обучения (на мешке слов модель обучалась более 20 минут)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для CatBoost\n",
    "pipeline_cat_tf = Pipeline(steps=[\n",
    "    ('vectorizer', count_tf_idf),\n",
    "    ('dt_estimator', CatBoostClassifier(eval_metric = 'F1', iterations=50, verbose=0, \\\n",
    "                                        random_state=2501, has_time=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = [{\n",
    "    'dt_estimator__learning_rate': [0.03, 0.1],\n",
    "    'dt_estimator__depth': [1, 10],\n",
    "    'dt_estimator__l2_leaf_reg': [3, 5, 7, 9]\n",
    "}]\n",
    "\n",
    "grid_search_cat_down_tf = GridSearchCV(pipeline_cat_tf, param_grid, cv=3, scoring='f1', n_jobs=1)\n",
    "grid_search_cat_down_tf.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "f1_catboost_down_tf = grid_search_cat_down_tf.best_score_\n",
    "\n",
    "print(f'F1 CatBoost: {f1_catboost_down_tf}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_cat_down_tf.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика F1 хорошая, лучше, чем у CatBoost на мешке слов. Также обучение модели длилось очень долго - почти 2 часа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для SGDClassifier\n",
    "pipeline_sgd_tf = Pipeline(steps=[\n",
    "    ('vectorizer', count_tf_idf),\n",
    "    ('dt_estimator', SGDClassifier(random_state=2501, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = [{\n",
    "    'dt_estimator__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'dt_estimator__loss': ['hinge', 'log', 'modified_huber'],\n",
    "    'dt_estimator__eta0': [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "}]\n",
    "\n",
    "grid_search_sgd_down_tf = GridSearchCV(pipeline_sgd_tf, param_grid, cv=3, scoring='f1', n_jobs=1)\n",
    "grid_search_sgd_down_tf.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "f1_sgd_down_tf = grid_search_sgd_down_tf.best_score_\n",
    "\n",
    "print(f'F1 SGD: {f1_sgd_down_tf}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_sgd_down_tf.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика F1 чуть выше, чем при мешке слов, время на обучение затрачено такое же."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наивный Байес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наивный Байес Complement\n",
    "pipeline_nbc_tf = Pipeline(steps=[\n",
    "    ('vectorizer', count_tf_idf),\n",
    "    ('dt_estimator', ComplementNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = [{\n",
    "    'dt_estimator__alpha': [1.0, 0.0, 0.5],\n",
    "    'dt_estimator__fit_prior': [True, False]\n",
    "}]\n",
    "\n",
    "grid_search_nbc_tf = GridSearchCV(pipeline_nbc_tf, param_grid, cv=3, scoring='f1', n_jobs=1)\n",
    "grid_search_nbc_tf.fit(features_train, target_train)\n",
    "f1_nbc_tf = grid_search_nbc_tf.best_score_\n",
    "\n",
    "print(f'F1 Наивного Байеса Complement: {f1_nbc_tf}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_nbc_tf.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наивный Байес Бернулли\n",
    "pipeline_nbc_ber_tf = Pipeline(steps=[\n",
    "    ('vectorizer', count_tf_idf),\n",
    "    ('dt_estimator', BernoulliNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = [{\n",
    "    'dt_estimator__alpha': [1.0, 0.0, 0.5],\n",
    "    'dt_estimator__fit_prior': [True, False]\n",
    "}]\n",
    "\n",
    "grid_search_nbc_ber_tf = GridSearchCV(pipeline_nbc_ber_tf, param_grid, cv=3, scoring='f1', n_jobs=1)\n",
    "grid_search_nbc_ber_tf.fit(features_train, target_train)\n",
    "f1_nbc_ber_tf = grid_search_nbc_ber_tf.best_score_\n",
    "\n",
    "print(f'F1 Наивного Байеса Бернулли: {f1_nbc_ber_tf}') \n",
    "print(f'Лучшие гиперпараметры: {grid_search_nbc_ber_tf.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и с мешком слов, Наивный Байес с TF-IDF не справился с заданным порогом метрики F1. Но скорость его обучения впечатляет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# соберем все в одной таблице\n",
    "total_tf = pd.DataFrame(columns=['F1'],\n",
    "                    index=['Случайный лес несбаланс.выборки', \n",
    "                           'Случайный лес balanced', \n",
    "                           'Логистическая регрессия balanced',\n",
    "                           'CatBoost',\n",
    "                           'SGDClassifier',\n",
    "                          'Наивный Байес Complement',\n",
    "                          'Наивный Байес Бернулли'],\n",
    "                    data=[f1_forest_tf, f1_forest_cwb_tf, f1_logreg_cwb_tf,\n",
    "                          f1_catboost_down_tf, f1_sgd_down_tf, f1_nbc_tf, \n",
    "                          f1_nbc_ber_tf])\n",
    "total_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tf.sort_values(by='F1', ascending=False).plot.barh(y='F1', figsize=(12,5), color='green')\n",
    "plt.title('Сравнение F1 моделей')\n",
    "plt.xlabel('F1')\n",
    "plt.ylabel('Модель')\n",
    "plt.axvline(x=0.75, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При использовании векторизации TF-IDF метрики F1 получились чуть лучше, также в некоторых моделях уменьшилось время обучения модели. Лучшую метрику показала модель SGD, но она обучалась на сбалансированной уменьшенной выборке. Для проверки на тестовых данных нам нужна полный датасет. Поэтому лучшая и единственная в данном случае модель - Логистическая регрессия с параметром сбалансированности классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эмбеддинги BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем преобразовать текст с помощью эмбеддингов модели BERT и посмотрим на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим предобученный англоязычный токенизатор\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предобученная модель - на этой ячейке все умирает. Пробовала еще загружать так: \n",
    "# model_bert = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "model_bert = AutoModelForMaskedLM.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизируем все комментарии\n",
    "tokenized = data['text'].progress_apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате обучения с помощью векторизации Мешка слов и TF-IDF кодирования лучшими моделями оказались Логистическая регрессия. F1 метрика с TF-IDF чуть выше, также скорость обучения в 5 раз быстрее (22 минуты против 4). Будем проверять на тестовой выборке именно Логистическую регрессию с TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'F1 логистической регрессии с мешком слов: {f1_logreg_cwb_bow}')\n",
    "print(f'F1 логистической регрессии с TF-IDF: {f1_logreg_cwb_tf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "\n",
    "\n",
    "Наталья о работе с датасетами:    \n",
    "\n",
    "1. На train мы обучаем\n",
    "2. По валидации смотрим на результаты обучения (следим чтобы не было переобучения и/или делаем подбор гиперпараметров).  И выбираем лучшую модель.  Валидационную можно создать самим, но лучше использовать GridSearch где кроссвалидация осуществляется автоматически (GridSearchCV хранит оценку по валидации в best_score_). \n",
    "3. Тестовая (out-of_sample) у нас для финальной проверки, когда определена лучшая модель с конкретными гиперпараметрами. Это делается для того, чтобы мы даже незначительным образом не \"подгонялись\" под тестовую выборку. Ведь на train модели обучаются, по валидиации подгоняются гиперпараметры. Эти данные модели \"знают\". А test (out-of-sample) это уже моделирование прогноза на реальных данных и ситуации когда у нас есть уже лучшая модель (в рельности у нас же не может быть несоклько прогнозов, что то в любом случаи надо выбирать). Вот поэтому такая двухуровневая проверка на подгонку. Кроме того использование мноих моделей с разными гиперпараметрами это тоже подгонка, поэтому выбирая одну и тестируя только ее, мы тем самым боремся с подгонкой через использование многих-многих моделей, когда результат хорош не потому что мы данные почистили хорошо, моделировали правильно итд итп, а потому что из многих моделей хоть какая то случайно \"сыграет\". \n",
    "    \n",
    "А как сделал ты может сложиться впечатление что мы на тестовой по прежнему что то выбираем, но выбор уже сделан на валидации, и если лучшая модель выбранная на валидационной покажет на test результат хуже требуемого, мы начнем процесс моделирования сначала (а не будем такие - \"а давай попробуем на тесте модель которая на валидации не была лучшей, может она нам на test даст нужное качество\").       \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background: #00ffff\">\n",
    "<b>Комментарий студента</b>\n",
    "    <br>Поняла, спасибо. Просто в одном из прошлых проектов нужно было как раз выбрать лучшую модель после теста, поэтому в голове отложилось, что так можно. Исправляюсь.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "👍\n",
    "\n",
    "\n",
    "\n",
    " [Вот](https://towardsdatascience.com/why-do-we-need-a-validation-set-in-addition-to-training-and-test-sets-5cf4a65550e0   ) тут можно дополнительно почитать.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "    \n",
    "    \n",
    "Совет:\n",
    "\n",
    "\n",
    "Только не надо воспринимать  GS как способ получить .best_params_, чтобы подставить их в модель и обучить на них. GS это сделал уже и модельку положил тут: .best_estimator_\n",
    "    \n",
    "Ты везде использовала одно и тоже название grid_search, а могла давать разные названия (например grid_search_sgd_downsampled), и тогда опять обучать модель на найденных лучших гиперпараметры уже не нужно было достаточно было    grid_search_sgd_downsampled.best_estimator_.predict(features_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background: #00ffff\">\n",
    "<b>Комментарий студента</b>\n",
    "    <br>Done<br>\n",
    "    Везде использовала разные названия + best_estimator_\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "Принято\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_valid = grid_search_logreg_cwb_tf.best_estimator_.predict(features_test)\n",
    "f1_test = f1_score(target_test, predicted_valid)\n",
    "\n",
    "print(f'F1 Логистической регрессии на несбалансированных выборках: {f1_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель справилась на тестовой выборке, метрика F1 = 0.7528256650302546. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Если студент получил на тесте accuraсy  выше 0,75, это считается приемлемым результатом. Тобой подбиралась лучшая комбинация не по одному гиперпараметру и вот он результат!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет: \n",
    "\n",
    "Что может помочь добиться лучшего результата (от простого)? \n",
    "\n",
    "- использовать stratify. Done!\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "- учесть дисбаланс класов в таргете. (но не oversampling, это скользкая дорожка, через class_weight) Done!\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "- полезно настраивать векторайзеры (тут пригодится pipeline) Done!\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "- подобрать лучшие гиперпараметры с использованием кроссвалидации (тут пригодится GridSearchCV) Done!\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "- сгенерировать новые фичи, например  например посчитать число слов в тексте, длину слов итп итд. Или с помощью [тематического моделирования](https://pythobyte.com/python-for-nlp-topic-modeling-8fb3d689/) / использовать ембединги слов, учитывающие семантику, например [word2vec](https://radimrehurek.com/gensim/models/word2vec.html)) \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "- попробовать другие модели. проект своеобразный выбор между вычислительными ограничениями (много примеров, расчеты могут затянуться) и задачей получить хорошую метрику (как это и бывает на практике), поэтому советовать \"тяжелые\", но мощные модели, чтобы у тебя все окончательно не повисло не буду (хотя есть вариант попробовать сделать на GPU).  А вот попробовать простые модели: SVC, NBC, логистическая регрессия, которые хорошо отработают с разряженными матрицами, могу. Простые модели - зато используем весь датасет. \n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background: #00ffff\">\n",
    "<b>Комментарий студента</b>\n",
    "    <br>Тематическое моделирование почитала, но не поняла, как его применить. Например, я добавляю новые столбцы с фичами (тематика и пр.), как потом этот столбец использовать для обучения? Мы же модели подаем только лемматизированный очищенный текст - один столбец. Или я что-то упустила?🙈 Или это нужно запускать параллельно при векторизации в pipeline и там само все сделается?<br><br>\n",
    "    Добавила модель Наивного Байеса. Пыталась еще метод опорных векторов, но у меня все зависло и я так и не дождалась результата даже на уменьшенных выборках.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "Хороший вопрос. Это называется насоветоваk студенту )  Я бы начал [с](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion)  [или](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer), [тут](https://towardsdatascience.com/pipeline-columntransformer-and-featureunion-explained-f5491f815f) расписано. Готовых примеров реализации в коде для тематического моделирования я не нашёл. Пока только так )\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе данного проекта было сделано:\n",
    "- первичная предобработка данных для дальнейшего обучения моделей\n",
    "- лемматизация и очистка текстов от \"мусора\"\n",
    "- создано \"облако тегов\" самых часто используемых слов\n",
    "- сделаны векторизации корпуса двумя способами: Мешок слов (BOW) и TF-IDF-кодирование\n",
    "- обучены пять моделей на сбалансированных и несбалансированных выборках\n",
    "- подобраны лучшие гиперпараметры с помощью кросс-валидации\n",
    "- выбрали лучшую модель по F1 и скорости обучения: Логистическая регрессия с TF-IDF-кодированием, обученная на несбалансированных выборках с аргументом class_weight='balanced'\n",
    "- лучшая модель проверена на тестовой выборке \n",
    "- F1 лучшей модели на тестовой выборке: 0.7528256650302546"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Наталья, здорово что в конце расписаны все этапы работы. Это важно потому что когда проект захочет посмотреть будущий работодатель (или начальник), у него может не быть времени на подробный разбор кода. Вероятнее всего он бегло просмотрит код, а из общего вывода захочет получить представление о всей работе.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Наталья, у тебя старательно выполненная работа, все четко, осмысленно. Некоторые пункты выполнены в большем чем требуется обьеме (pipeline, поработала с дисбалансом). Отличные графики и таблички. Выводы присутствуют, они четкие и подробные. Нет проблем с комментированием кода,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Я оставил небольшие советы и вопросики (если есть время и желание можешь воспользоваться/ответить).\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Обязательное к исправлению:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- WordNetLemmatizer используем с POS - тег \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- стопслова не убраны, а это важно, так как они не несут смысловую нагрузку и могут подпортить наши результаты \n",
    "\n",
    "\n",
    "\n",
    "- на test датасете тестируем только лучшую модель (нарушена логика использования датасетов при моделировании)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "Жду исправлений, для принятия проекта. Если какие то вопросы, то сразу спрашивай ) \n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background: #00ffff\">\n",
    "<b>Комментарий студента</b>\n",
    "    <br>Спасибо еще раз за все советы и рекоммендации.<br><br>\n",
    "    Если эта часть проекта готова, не принимай ее пока, пожалуйста! Я попробую еще BERT поковырять - есть несколько дней до дедлайна 🤗\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Спасибо за работу!   Красное исправлено, многие желтые советы использованы, на  вопросы есть ответы  (это все было по желанию), значит стремишься развиваться, а желание и интерес это главное.  \n",
    "\n",
    "Понял, посылаю на 3 ) Ты очень щепетильно подходишь (в хорошем смысле этого слова): выбираешь, пробуешь разные варианты - задатки самого настоящего датасаентиста )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "268px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
