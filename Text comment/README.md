# Выявление токсичных комментариев

## Задача
Обучить модель классифицировать комментарии на позитивные и негативные (токсичные). Метрика качества F1 должна быть не меньше 0.75.

## Данные
Находятся в файле "toxic_comments.csv". В столбце "text" содержится текст комментариев, а в "toxic" — целевой признак (0 и 1).

## Используемые библиотеки
- pandas
- matplotlib
- nltk
- re
- torch
- transformers
- sklearn
- catboost
- lightgbm
- wordcloud

## Результаты
1. Произведена лемматизация, токенизация и векторизация данных двумя способами: Мешок слов (BOW) и TF-IDF-кодирование.
2. Обучены пять моделей на сбалансированных и несбалансированных выборках, подобраны лучшие гиперпараметры с помощью кросс-валидации.
3. Выбрана лучшая модель по F1 и скорости обучения: Логистическая регрессия с TF-IDF-кодированием, обученная на несбалансированных выборках с аргументом class_weight='balanced'. F1 лучшей модели на тестовой выборке: 0.75282.
